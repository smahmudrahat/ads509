{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"2020_Conventions.db\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'party', 'TEXT', 0, None, 0),\n",
       " (1, 'night', 'INTEGER', 0, None, 0),\n",
       " (2, 'speaker', 'TEXT', 0, None, 0),\n",
       " (3, 'speaker_count', 'INTEGER', 0, None, 0),\n",
       " (4, 'time', 'TEXT', 0, None, 0),\n",
       " (5, 'text', 'TEXT', 0, None, 0),\n",
       " (6, 'text_len', 'TEXT', 0, None, 0),\n",
       " (7, 'file', 'TEXT', 0, None, 0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "\n",
    "# Inspect the table structure\n",
    "cursor.execute(\"PRAGMA table_info(conventions);\")\n",
    "columns = cursor.fetchall()\n",
    "\n",
    "# Fetch a few rows to see the data\n",
    "cursor.execute(\"SELECT * FROM conventions LIMIT 5;\")\n",
    "sample_data = cursor.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_tokenize(text):\n",
    "    # lower the text \n",
    "    text = text.lower()\n",
    "    # remove non alphabetic character \n",
    "    text = re.sub(r\"[^a-z\\s#]\", '', text)\n",
    "    # tokenize the text \n",
    "    tokens = word_tokenize(text)\n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "conn = sqlite3.connect(\"2020_Conventions.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = \"SELECT text, party FROM conventions\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "rows\n",
    "\n",
    "for row in rows:\n",
    "    text, party = row\n",
    "    tokens = clean_tokenize(text)\n",
    "    convention_data.append((tokens,party))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['joe',\n",
       "   'bidens',\n",
       "   'america',\n",
       "   'radical',\n",
       "   'left',\n",
       "   'get',\n",
       "   'whatever',\n",
       "   'want',\n",
       "   'get',\n",
       "   'pay',\n",
       "   'theyve',\n",
       "   'already',\n",
       "   'taken',\n",
       "   'joe',\n",
       "   'biden',\n",
       "   'democratic',\n",
       "   'party',\n",
       "   'dont',\n",
       "   'let',\n",
       "   'take',\n",
       "   'america'],\n",
       "  'Republican'),\n",
       " (['oath'], 'Republican')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2327 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "     # Your code here\n",
    "\n",
    "    text_words = set(text.split())\n",
    "    ret_dict = dict()\n",
    "    \n",
    "    for word in text_words:\n",
    "         #print(word)\n",
    "         if word in fw:\n",
    "              ret_dict[word] = True\n",
    "\n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'donald': True, 'president': True}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_features(\"donald is the president\",feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(' '.join(text),feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                  defund = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "`Republican-Associated Words:` Words like \"china\", \"enforcement\", \"destroy\", \"freedoms\", \"crime\", \"media\", \"defense\", \"defund\", \"religion\", \"trade\", \"flag\", and \"greatness\" are strongly associated with Republican speeches. These words have high odds ratios indicating they are significantly more likely to appear in Republican text. The presence of words like \"china\" and \"trade\" suggests a focus on international relations and economic policies, which were likely significant topics for Republicans during the convention. </br>\n",
    "`Democratic-Associated Words:` Words like \"votes\" and \"climate\" are strongly associated with Democratic speeches, though fewer words are listed for Democrats compared to Republicans in the most informative features. Words like \"climate\" indicate an emphasis on environmental issues in Democratic speeches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming\n",
    "cong_db.close()  # Close the database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(664656,\n",
       " [(b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq',\n",
       "   'Republican'),\n",
       "  (b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6',\n",
       "   'Republican'),\n",
       "  (b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA',\n",
       "   'Republican'),\n",
       "  (b'\"The trouble with Socialism is that eventually you run out of other people\\'s money.\" - Margaret Thatcher https://t.co/X97g7wzQwJ',\n",
       "   'Republican'),\n",
       "  (b'\"The trouble with socialism is eventually you run out of other people\\'s money\" \\xe2\\x80\\x93 Thatcher. She\\'ll be sorely missed. http://t.co/Z8gBnDQUh8',\n",
       "   'Republican')])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare tweet_data with sublists\n",
    "tweet_data = [(row[2], row[1]) for row in results]  # (tweet_text, party)\n",
    "\n",
    "len(tweet_data), tweet_data[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democratic tweets: 376125\n",
      "Republican tweets: 288531\n",
      "Classifier accuracy: 0.6140\n",
      "Here's our (cleaned) tweet: b'Interesting read. http://t.co/BgcVCNpACE'\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'This week, the GOP will kick off their Natl Convention. Will we hear about what unites us or divides us? https://t.co/RmliqMGFtv #RNCinCLE'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'@patsox23 Done'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Will be on @CNNnewsroom at 1:15 pm PT / 4:15 pm ET today.'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'.@SenJohnThune &amp; @SenToomey: Proposed SEC #JOBSAct regulations would have adverse effects on #SmallBiz &amp; investors   http://t.co/9I94uNhjS8'\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Equal protection under the law, women\\xe2\\x80\\x99s suffrage, and ending slavery are not problems; they are the embodiment of our capacity as a nation to grow and conquer the worst demons of our history. https://t.co/XWB84JIPzZ'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"Well isn't this exciting. \\n#ALDems #BlueTsunami #Freethe6th https://t.co/wSSLL10cjr\"\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'It is a wonder of nature that @SpeakerRyan can walk upright without a spine. His fear of the NRA is palpable. https://t.co/mi2I7ewEfY'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'RIP, Diane. We miss you already. I know you &amp; Fuzzy Face will watch over us as we continue to fight the good fight as you would do. \\xe2\\x9c\\x9d\\xef\\xb8\\x8f https://t.co/xJKWdni9QW'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Capitol Hill office buildings are flooded. I KNEW God was going to punish us for Helsinki. Thanks, #TrumpPutin. https://t.co/PsHqkLIucT'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "# Clean and tokenize function\n",
    "def clean_tokenize(text):\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode('utf-8')  # Decode bytes to string\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Check the balance of the dataset\n",
    "party_counts = defaultdict(int)\n",
    "for tweet, party in tweet_data:\n",
    "    party_counts[party] += 1\n",
    "\n",
    "print(f\"Democratic tweets: {party_counts['Democratic']}\")\n",
    "print(f\"Republican tweets: {party_counts['Republican']}\")\n",
    "\n",
    "# Ensure we have a balanced dataset for training\n",
    "dem_tweets = [tp for tp in tweet_data if tp[1] == 'Democratic']\n",
    "rep_tweets = [tp for tp in tweet_data if tp[1] == 'Republican']\n",
    "min_tweet_count = min(len(dem_tweets), len(rep_tweets))\n",
    "\n",
    "balanced_tweet_data = dem_tweets[:min_tweet_count] + rep_tweets[:min_tweet_count]\n",
    "random.shuffle(balanced_tweet_data)\n",
    "\n",
    "# Convert the tokens back into strings for conv_features\n",
    "featuresets = [(conv_features(' '.join(clean_tokenize(text)), feature_words), party) for (text, party) in balanced_tweet_data]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "test_size = int(0.2 * len(featuresets))\n",
    "train_set, test_set = featuresets[test_size:], featuresets[:test_size]\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "print(f\"Classifier accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Sample 10 tweets\n",
    "tweet_data_sample = random.choices(tweet_data, k=10)\n",
    "\n",
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    #estimated_party = 'Gotta fill this in'\n",
    "    tokens = clean_tokenize(tweet)\n",
    "    # convert to feature vector \n",
    "    features = conv_features(\"\".join(tokens), feature_words)\n",
    "    # estimate the party \n",
    "    estimated_party = classifier.classify(features)\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: Republican, Estimated: Republican, Count: 1662\n",
      "Actual: Republican, Estimated: Democratic, Count: 2699\n",
      "Actual: Democratic, Estimated: Republican, Count: 799\n",
      "Actual: Democratic, Estimated: Democratic, Count: 4842\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of counts by actual party and estimated party\n",
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp    \n",
    "    # Clean and tokenize the tweet\n",
    "    tokens = clean_tokenize(tweet)\n",
    "    # Convert to feature vector\n",
    "    features = conv_features(' '.join(tokens), feature_words)\n",
    "    # Estimate the party using the classifier\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score:\n",
    "        break\n",
    "\n",
    "# Print the results\n",
    "for actual_party in results:\n",
    "    for estimated_party in results[actual_party]:\n",
    "        print(f\"Actual: {actual_party}, Estimated: {estimated_party}, Count: {results[actual_party][estimated_party]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 1662, 'Democratic': 2699}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 799, 'Democratic': 4842})})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "- The classifier's accuracy is 61.40%, which suggests that while it is somewhat effective, there is significant room for improvement. The classifier correctly predicts the party for about 61% of the tweets. \n",
    "\n",
    "**`Republican Tweets:`**\n",
    "\n",
    "- Correctly classified: 1,662 </br>\n",
    "- Incorrectly classified as Democratic: 2,699 </br>\n",
    "The classifier has a higher rate of misclassification for Republican tweets, with more tweets being incorrectly classified as Democratic than correctly classified as Republican. </br>\n",
    "\n",
    "**`Democratic Tweets:`**\n",
    "\n",
    "Correctly classified: 4,842 </br>\n",
    "- Incorrectly classified as Republican: 799 </br>\n",
    "- The classifier performs better on Democratic tweets, with a higher number of correct classifications compared to incorrect ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
